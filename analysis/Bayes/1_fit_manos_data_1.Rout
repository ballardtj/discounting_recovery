WARNING: unknown option '--1'


R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> rm(list=ls())
> 
> ###read in the arguments listed at the command line
> args <- commandArgs(trailingOnly = F)
> 
> print(args)
[1] "/gpfs1/homes/uqtballa/.linuxbrew/Cellar/r/3.3.1_2/lib/R/bin/exec/R"
[2] "-f"                                                                
[3] "/QRISdata/Q0992/analysis/Bayes/1_fit_manos_data.R"                 
[4] "--restore"                                                         
[5] "--save"                                                            
[6] "--no-readline"                                                     
[7] "--no-save"                                                         
[8] "--no-restore"                                                      
[9] "--1"                                                               
> 
> i <- args[length(args)]
> i <- strsplit(i,"--")[[1]][2]
> i <- as.numeric(i)
> 
> print(i)
[1] 1
> 
> #set working directory
> setwd("/QRISdata/Q0992")
> 
> #set seed
> set.seed(12345)
> 
> #load packages
> library(tidyverse)
── Attaching packages ─────────────────────────────────────── tidyverse 1.2.1 ──
✔ ggplot2 2.2.1     ✔ purrr   0.2.4
✔ tibble  1.4.2     ✔ dplyr   0.7.4
✔ tidyr   0.7.2     ✔ stringr 1.3.0
✔ readr   1.1.1     ✔ forcats 0.3.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
> library(rstan)
Loading required package: StanHeaders
rstan (Version 2.17.3, GitRev: 2e1f913d3ca3)
For execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores()).
To avoid recompilation of unchanged Stan programs, we recommend calling
rstan_options(auto_write = TRUE)

Attaching package: ‘rstan’

The following object is masked from ‘package:tidyr’:

    extract

> 
> #load data
> dat=readRDS(file="data/raw/data_delay_lba2018.rds")
> 
> #format data for model fitting
> dat$m_a = dat$amount
> dat$d_a = dat$delay
> dat$m_b = 100
> dat$d_b = 0    #note: b is smaller, sooner option
> dat$choose_a = dat$Choice
> Nsubj = length(unique(dat$subject))
> 
> #prep data
> data_list = list(Ntotal = dim(dat)[1],
+                  Nsubj = Nsubj,
+                  subj = dat$subject,
+                  y=dat$choose_a,
+                  d_a = dat$d_a,
+                  d_b = dat$d_b,
+                  m_a = dat$m_a,
+                  m_b = dat$m_b)
> 
> models = c('hyperbolic',
+            'exponential',
+            'hyperbolic_gm',
+            'prop_diff',
+            'tradeoff',
+            'ITCH',
+            'const_sens',
+            'mazur1987',
+            'loewenstein1992',
+            'mcclure2007',
+            'killeen2009')
> 
> 
> fit=stan(file=paste0("models/",models[i],".stan"),
+          data=data_list,
+          iter=2000,
+          warmup=1000,
+          cores=8,
+          chains=8,
+          control=list(max_treedepth=20,adapt_delta=0.99),
+          seed=12345)

SAMPLING FOR MODEL 'hyperbolic' NOW (CHAIN 1).

Gradient evaluation took 0.010495 seconds
1000 transitions using 10 leapfrog steps per transition would take 104.95 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'hyperbolic' NOW (CHAIN 2).

Gradient evaluation took 0.008165 seconds
1000 transitions using 10 leapfrog steps per transition would take 81.65 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'hyperbolic' NOW (CHAIN 3).

Gradient evaluation took 0.008013 seconds
1000 transitions using 10 leapfrog steps per transition would take 80.13 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'hyperbolic' NOW (CHAIN 4).

Gradient evaluation took 0.00826 seconds
1000 transitions using 10 leapfrog steps per transition would take 82.6 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'hyperbolic' NOW (CHAIN 5).

Gradient evaluation took 0.008788 seconds
1000 transitions using 10 leapfrog steps per transition would take 87.88 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'hyperbolic' NOW (CHAIN 6).

Gradient evaluation took 0.008704 seconds
1000 transitions using 10 leapfrog steps per transition would take 87.04 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'hyperbolic' NOW (CHAIN 7).

Gradient evaluation took 0.009544 seconds
1000 transitions using 10 leapfrog steps per transition would take 95.44 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'hyperbolic' NOW (CHAIN 8).

Gradient evaluation took 0.009686 seconds
1000 transitions using 10 leapfrog steps per transition would take 96.86 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 573.433 seconds (Warm-up)
               571.337 seconds (Sampling)
               1144.77 seconds (Total)

Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 764.322 seconds (Warm-up)
               387.065 seconds (Sampling)
               1151.39 seconds (Total)

Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 645.763 seconds (Warm-up)
               630.024 seconds (Sampling)
               1275.79 seconds (Total)

Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 737.253 seconds (Warm-up)
               702.593 seconds (Sampling)
               1439.85 seconds (Total)

Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 918.66 seconds (Warm-up)
               573.696 seconds (Sampling)
               1492.36 seconds (Total)

Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 1080.63 seconds (Warm-up)
               642.572 seconds (Sampling)
               1723.2 seconds (Total)

Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 1171.78 seconds (Warm-up)
               622.182 seconds (Sampling)
               1793.96 seconds (Total)

Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 1082.35 seconds (Warm-up)
               1096.95 seconds (Sampling)
               2179.3 seconds (Total)

> 
> save(fit,file=paste0("data/derived/fits/fit_Bayes_",models[i],".RData"))
> 
> proc.time()
     user    system   elapsed 
10050.608     4.708  2252.529 
