WARNING: unknown option '--11'


R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> rm(list=ls())
> 
> ###read in the arguments listed at the command line
> args <- commandArgs(trailingOnly = F)
> 
> print(args)
[1] "/gpfs1/homes/uqtballa/.linuxbrew/Cellar/r/3.3.1_2/lib/R/bin/exec/R"
[2] "-f"                                                                
[3] "/QRISdata/Q0992/analysis/Bayes/1_fit_manos_data.R"                 
[4] "--restore"                                                         
[5] "--save"                                                            
[6] "--no-readline"                                                     
[7] "--no-save"                                                         
[8] "--no-restore"                                                      
[9] "--11"                                                              
> 
> i <- args[length(args)]
> i <- strsplit(i,"--")[[1]][2]
> i <- as.numeric(i)
> 
> print(i)
[1] 11
> 
> #set working directory
> setwd("/QRISdata/Q0992")
> 
> #set seed
> set.seed(12345)
> 
> #load packages
> library(tidyverse)
── Attaching packages ─────────────────────────────────────── tidyverse 1.2.1 ──
✔ ggplot2 2.2.1     ✔ purrr   0.2.4
✔ tibble  1.4.2     ✔ dplyr   0.7.4
✔ tidyr   0.7.2     ✔ stringr 1.3.0
✔ readr   1.1.1     ✔ forcats 0.3.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
> library(rstan)
Loading required package: StanHeaders
rstan (Version 2.17.3, GitRev: 2e1f913d3ca3)
For execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores()).
To avoid recompilation of unchanged Stan programs, we recommend calling
rstan_options(auto_write = TRUE)

Attaching package: ‘rstan’

The following object is masked from ‘package:tidyr’:

    extract

> 
> #load data
> dat=readRDS(file="data/raw/data_delay_lba2018.rds")
> 
> #format data for model fitting
> dat$m_a = dat$amount
> dat$d_a = dat$delay
> dat$m_b = 100
> dat$d_b = 0    #note: b is smaller, sooner option
> dat$choose_a = dat$Choice
> Nsubj = length(unique(dat$subject))
> 
> #prep data
> data_list = list(Ntotal = dim(dat)[1],
+                  Nsubj = Nsubj,
+                  subj = dat$subject,
+                  y=dat$choose_a,
+                  d_a = dat$d_a,
+                  d_b = dat$d_b,
+                  m_a = dat$m_a,
+                  m_b = dat$m_b)
> 
> models = c('hyperbolic',
+            'exponential',
+            'hyperbolic_gm',
+            'prop_diff',
+            'tradeoff',
+            'ITCH',
+            'const_sens',
+            'mazur1987',
+            'loewenstein1992',
+            'mcclure2007',
+            'killeen2009')
> 
> 
> fit=stan(file=paste0("models/",models[i],".stan"),
+          data=data_list,
+          iter=2000,
+          warmup=1000,
+          cores=8,
+          chains=8,
+          control=list(max_treedepth=20,adapt_delta=0.99),
+          seed=12345)

SAMPLING FOR MODEL 'killeen2009' NOW (CHAIN 1).

Gradient evaluation took 0.017162 seconds
1000 transitions using 10 leapfrog steps per transition would take 171.62 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'killeen2009' NOW (CHAIN 2).

Gradient evaluation took 0.014401 seconds
1000 transitions using 10 leapfrog steps per transition would take 144.01 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'killeen2009' NOW (CHAIN 3).

Gradient evaluation took 0.015775 seconds
1000 transitions using 10 leapfrog steps per transition would take 157.75 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'killeen2009' NOW (CHAIN 4).

Gradient evaluation took 0.016489 seconds
1000 transitions using 10 leapfrog steps per transition would take 164.89 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'killeen2009' NOW (CHAIN 5).

Gradient evaluation took 0.015946 seconds
1000 transitions using 10 leapfrog steps per transition would take 159.46 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'killeen2009' NOW (CHAIN 6).

Gradient evaluation took 0.01648 seconds
1000 transitions using 10 leapfrog steps per transition would take 164.8 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'killeen2009' NOW (CHAIN 7).

Gradient evaluation took 0.01646 seconds
1000 transitions using 10 leapfrog steps per transition would take 164.6 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'killeen2009' NOW (CHAIN 8).

Gradient evaluation took 0.016548 seconds
1000 transitions using 10 leapfrog steps per transition would take 165.48 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 28918.2 seconds (Warm-up)
               16358.1 seconds (Sampling)
               45276.3 seconds (Total)

Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 24022.2 seconds (Warm-up)
               26063.7 seconds (Sampling)
               50085.9 seconds (Total)

Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 25062 seconds (Warm-up)
               26377 seconds (Sampling)
               51439 seconds (Total)

Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 25239.6 seconds (Warm-up)
               26492.6 seconds (Sampling)
               51732.2 seconds (Total)

Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 25732.1 seconds (Warm-up)
               26302.6 seconds (Sampling)
               52034.7 seconds (Total)

Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 26584.9 seconds (Warm-up)
               26316.4 seconds (Sampling)
               52901.3 seconds (Total)

Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 34068.1 seconds (Warm-up)
               25636.5 seconds (Sampling)
               59704.7 seconds (Total)

Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 29260.1 seconds (Warm-up)
               49149.2 seconds (Sampling)
               78409.3 seconds (Total)

> 
> save(fit,file=paste0("data/derived/fits/fit_Bayes_",models[i],".RData"))
> 
> proc.time()
      user     system    elapsed 
362658.189    597.546  78529.534 
